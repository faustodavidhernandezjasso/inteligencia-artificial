{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cadenas de Markov \n",
    "También son llamados como procesos de Markov.\n",
    "## Definición\n",
    "Es un proceso estocástico con la propiedad de que para cualquier conjunto sucesivo de \n",
    "$n$ tiempos tales que $t_{1} < t_{2} < \\dotsc < t_{n}$ se tiene que:\n",
    "$$\n",
    "    P_{1 | n - 1}\\left(y_{n} , t_{n} | y_{1}, t_{1}; \\dotsc ; y_{n - 1}, t_{n-1}\\right) = P_{1 | 1}\\left( y_n, t_n | y_{n - 1}, t_{n - 1}\\right)\n",
    "$$\n",
    "Esto es que la densidad de probabilidad condicionada a $t_{n}$ dada el valor $y_{n-1}$ a $t_{n-1}$ está unívocamente determinada y no está afectada por lo que ocurre a tiempos anteriores. A $P_{1 | 1}$ se le conoce como la **probabilidad de transición**.\n",
    "## Definición (no tan formal).\n",
    "Una cadena o proceso de **Markov** es un proceso evolutivo que consiste de un número finito de estados en cual la probabilidad de que ocurra un evento depende solamente del evento inmediatamente anterior con unas probabilidades que están fijas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo\n",
    "## Mercado de valores\n",
    "![Cadena de Markov](imgs/Finance_Markov_chain_example_state_space.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los estados representan si un mercado bursátil (hipotético) muestra una tendencia alcista, bajista o de estancamiento durante una semana determinada. Según la gráfica dirigida anterior, sí pasamos una semana con tendencia alcista, entonces hay probabilidad de $90\\%$ que la siguiente semana sea con tendencia alcista, $7.5\\%$ de que sea una semana con tendencia a la baja y $2.5\\%$ de que la siguiente semana se estanque.\n",
    "Notemos que la gráfica anterior cumple lo siguiente:\n",
    "* **La pesos de todas las aristas que salen del estado $S$, suman $1$.**\n",
    "\n",
    "*Lo anterior se sigue de los axiomas de probabilidad.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matriz de transición. \n",
    "$$\n",
    "    A =\n",
    "    \\begin{bmatrix}\n",
    "        0.9  & 0.075 & 0.025 \\\\\n",
    "        0.15 & 0.8   & 0.05 \\\\\n",
    "        0.25 & 0.25  & 0.5\n",
    "    \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidad de un mercado alcista:   0.624963\n",
      "Probabilidad de un mercado bajista:   0.312889\n",
      "Probabilidad de un mercado estancado: 0.062148\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "matrix_transition = np.matrix([[0.9, 0.075, 0.025], [0.15, 0.8, 0.05], [0.25, 0.25, 0.5]]) # Bull Market Bear Market Stagnant market\n",
    "\n",
    "def random_walk(num_iter):\n",
    "    init = np.random.randint(0, 3)\n",
    "    bull_market = 0\n",
    "    bear_market = 0\n",
    "    stagnant_market = 0\n",
    "    for i in range(num_iter):\n",
    "        r = np.random.rand()\n",
    "        if init == 0:\n",
    "            if r < 0.9:\n",
    "                bull_market += 1\n",
    "            elif r >= 0.9 and r < 0.975:\n",
    "                init = 1\n",
    "                bear_market += 1\n",
    "            else:\n",
    "                init = 2\n",
    "                stagnant_market += 1\n",
    "        elif init == 1:\n",
    "            if r < 0.15:\n",
    "                init = 0\n",
    "                bull_market += 1\n",
    "            elif r >= 0.15 and r < 0.95:\n",
    "                bear_market += 1\n",
    "            else: \n",
    "                init = 2\n",
    "                stagnant_market += 1\n",
    "        else:\n",
    "            if r < 0.25:\n",
    "                init = 0\n",
    "                bull_market += 1\n",
    "            elif r >= 0.25 and r < 0.5:\n",
    "                init = 1\n",
    "                bear_market += 1\n",
    "            else:\n",
    "                stagnant_market += 1\n",
    "    return (bull_market, bear_market, stagnant_market)\n",
    "    \n",
    "markets = random_walk(1000000)\n",
    "total = markets[0] + markets[1] + markets[2]\n",
    "print(\"Probabilidad de un mercado alcista:   \" + str(markets[0] / total))\n",
    "print(\"Probabilidad de un mercado bajista:   \" + str(markets[1] / total))\n",
    "print(\"Probabilidad de un mercado estancado: \" + str(markets[2] / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribución estacionaria\n",
    "Sea $p^{(t)}$ la probabilidad de la distribución después de $t$ pasos de un *random walk*. Definimos la distribución de probabilidad $a^{(t)}$ como sigue:\n",
    "$$\n",
    "    a^{(t)} = \\frac{1}{t}\\left(p^{(0)} + p^{(1)} + \\dotsc + p^{(t - 1)}\\right)\n",
    "$$\n",
    "Es decir, ésta distribución de probabilidad **no cambia con el tiempo** en la cadena de Markov."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teorema Fundamental de las cadenas de Markov\n",
    "Para toda cadena de Markov conectada existe un único vector $\\pi$ de probabilidad que satisface:\n",
    "$$\n",
    "    \\pi P = \\pi\n",
    "$$\n",
    "donde $P$ es la matriz de transición asociada a la cadena de Markov. Más aún, para cualquier distribución inicial, $\\lim_{t \\to \\infty} a^{t}$ existe y es igual a $\\pi$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.625  0.3125 0.0625]]\n"
     ]
    }
   ],
   "source": [
    "bull_market = np.array([1, 0, 0]) # Supongamos que en el tiempo t = 0 es una semana con tendencia alcista.\n",
    "\n",
    "def find_distribution(matrix_transition, init):\n",
    "    pi = np.dot(init, matrix_transition)\n",
    "    while (pi != init).any():\n",
    "        init = pi\n",
    "        pi = np.dot(init, matrix_transition)\n",
    "    return pi\n",
    "\n",
    "print(find_distribution(matrix_transition, bull_market))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notemos que nuestra aproximación ejecutando *random walk*  es bastante buena y que de hecho cada que el número de iteraciones es más grande se va aproximando más al método con los vectores.\n",
    "\n",
    "Notemos que como el vector $\\pi$ denota una distribución de probabilidad entonces, el total de la suma de sus componentes es $1$.\n",
    "\n",
    "Así por lo que obtuvimos anteriormente concluimos lo siguiente:\n",
    "* El $62.5 \\%$ de las semanas serán a la alza.\n",
    "* El $31.25 \\%$ de las semanas se estancarán.\n",
    "* El $6.25 \\%$ de las semanas serán a la baja."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Irreducibilidad y Recurrencia\n",
    "![Cadena de Markov](imgs/cadena_de_markov_1.png)\n",
    "\n",
    "Veamos el estado $0$.\n",
    "Notemos que sí hacemos varios *random walk* sobre la cadena de Markov anterior iniciando en el estado $0$, habrá caminos que no saldrán del estado $0$, es decir, se quedarán en un **loop** sin embargo habrán caminos que saldrán del estado $0$ y no volverán, ya que no hay ninguna flecha que vaya al estado $0$ desde el estado $1$ o $2$. Así notemos que la probabilidad que tiene un *random walk* de revisitar el estado $0$ es menor que $1$, al estado $0$ se le conoce como **estado transitorio**.\n",
    "\n",
    "Supongamos ahora que queremos hacer un *random walk* desde el estado $1$, así podemos notar que después de un tiempo volvemos a visitar el estado $1$, notemos que ésto también lo cumple el estado $2$. Así la probabilidad de revisitar al estado $1$ es $1$ *(es análogo para el estado $2$)*. A estos estados se les conoce como **estados recurrentes**.\n",
    "\n",
    "## Reducible\n",
    "Decimos que una cadena de Markov es reducible sí existen en ella **estados transitorios**\n",
    "\n",
    "Notemos que a la cadena de Markov de ésta sección podemos hacer que todos sus estados sean **recurrentes** creando una flecha del estado $2$ al estado $0$.\n",
    "\n",
    "![Cadena de Markov con estados recurrentes](imgs/cadena_de_markov_2.png)\n",
    "\n",
    "A ésto le llamamos que una cadena de Markov sea irreducible, cuando todos sus estados son recurrentes.\n",
    "\n",
    "## Clases\n",
    "\n",
    "Una clase en una cadena de Markov es un subcadena de Markov que es irreducible.\n",
    "\n",
    "![Clases](imgs/cadena_de_markov_3.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cadenas de Markov en $n$ pasos\n",
    "## ¿Cuál es la probabilidad de alcanzar a un estado $j$ desde un estado $i$ en exactamente $n$ pasos?\n",
    "Así denotamos a $P_{ij}(n)$ como la probabilidad antes mencionada.\n",
    "## Ejemplo \n",
    "¿Cuál es la probabilidad de alcanzar el estado **Bull Market** desde el estado **Stagnant market** en exactamente $1$ paso?\n",
    "### Respuesta\n",
    "$0.25$\n",
    "¿Cuál es la probabilidad de alcanzar el estado **Bull Market** desde el estado **Stagnant market** en exactamente $2$ pasos?\n",
    "### Respuesta\n",
    "* **Stagnant Market** a **Bull Market** y de **Bull Market** a **Bull Market** esto es igual a $0.25 \\times 0.9$\n",
    "* **Stagnant Market** a **Stagnant Market** y de **Stagnant Market** a **Bull Market** esto es igual a $0.5 \\times 0.25$\n",
    "* **Stagnant Market** a **Bear Market** y de **Bear Market** a **Bull Market** esto es igual a $0.25 \\times 0.15$\n",
    "* **Total:** $0.25 \\times 0.9 + 0.5 \\times 0.25 + 0.25 \\times 0.15 = 0.3875$\n",
    "\n",
    "Notemos que lo anterior es:\n",
    "$A_{20} \\times A_{00} + A_{22} \\times A_{21} + A_{21} \\times A_{10}$\n",
    "Que es igual a:\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    A_{20} & A_{21} & A_{22}\n",
    "\\end{bmatrix}\n",
    "\\times\n",
    "\\begin{bmatrix}\n",
    "    A_{00} \\\\\n",
    "    A_{10} \\\\\n",
    "    A_{20}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "De manera general tenemos que:\n",
    "$$\n",
    "    P_{ij}(n) = A^{n}_{ij}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidad para 2 pasos: 0.03875000000000001\n"
     ]
    }
   ],
   "source": [
    "print(\"Probabilidad para 2 pasos: \" +  str(np.linalg.matrix_power(matrix_transition, 2)[0,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidad para los primeros 15 pasos iniciando desde Stagnant market y terminando en Bull market: \n",
      "Probabilidad para 1 pasos: 0.025\n",
      "Probabilidad para 2 pasos: 0.03875000000000001\n",
      "Probabilidad para 3 pasos: 0.04675000000000001\n",
      "Probabilidad para 4 pasos: 0.05167500000000001\n",
      "Probabilidad para 5 pasos: 0.05486500000000002\n",
      "Probabilidad para 6 pasos: 0.057018500000000014\n",
      "Probabilidad para 7 pasos: 0.05851810000000002\n",
      "Probabilidad para 8 pasos: 0.059585430000000016\n",
      "Probabilidad para 9 pasos: 0.06035636200000002\n",
      "Probabilidad para 10 pasos: 0.06091858820000002\n",
      "Probabilidad para 11 pasos: 0.06133114276000002\n",
      "Probabilidad para 12 pasos: 0.06163505132400002\n",
      "Probabilidad para 13 pasos: 0.06185947305040002\n",
      "Probabilidad para 14 pasos: 0.06202545021032003\n",
      "Probabilidad para 15 pasos: 0.062148319415248024\n"
     ]
    }
   ],
   "source": [
    "def probability_of_n_steps(matrix_transition, n, i, j):\n",
    "    return np.linalg.matrix_power(matrix_transition, n)[i, j]\n",
    "\n",
    "print(\"Probabilidad para los primeros 15 pasos iniciando desde Stagnant market y terminando en Bull market: \")\n",
    "for i in range(1, 16):\n",
    "    print(\"Probabilidad para \" + str(i) + \" pasos: \" + str(probability_of_n_steps(matrix_transition, i, 0, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo anterior es posible gracias al **Teorema Chapman-Kolmogorov** que establece lo siguiente:\n",
    "$$\n",
    "    P_{ij}(n) = \\sum_{k} P_{ik}(r) \\times P_{kj}(n-r)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_n_to_infty(transition_matrix):\n",
    "    init = transition_matrix\n",
    "    i = 2\n",
    "    transition_matrix = np.linalg.matrix_power(transition_matrix, i)\n",
    "    while (transition_matrix != init).any():\n",
    "        init = transition_matrix\n",
    "        i += 1\n",
    "        transition_matrix = np.linalg.matrix_power(init, i)\n",
    "    return transition_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicación de la cadenas de Markov: Generación de texto.\n",
    "Las cadenas de Markov nos ayudan a creer modelos de lenguaje.\n",
    "Para tener una cadena de Markov necesitamos lo siguiente:\n",
    "* Un conjunto de estados.\n",
    "* Transiciones entre éstos estados.\n",
    "\n",
    "Para generar texto vamos a hacer que las palabras sean estados.\n",
    "Supongamos que tenemos dos palabras $i$ y $j$ para calcular la probabilidad $P_{ij}$ lo único que necesitamos realizar es buscar en nuestro texto la probabilidad de que la siguiente palabra sea $j$ dado que la palabra actual es $i$ esto es:\n",
    "$$\n",
    "    P_{ij} = P\\left( n + 1 = j | n = i \\right)\n",
    "$$\n",
    "Sí no existe que la palabra $j$ está después que la palabra $i$ entonces la probabilidad será $0$\n",
    "## Ejemplo\n",
    "\n",
    "*My name is Sherlock Holmes. It is my business to know what other people do not know.*\n",
    "\n",
    "![Ejemplo](imgs/NPL1.png)\n",
    "\n",
    "El número de cada flecha es el número de veces que una palabra aparece previamente a la que apunta.\n",
    "\n",
    "Para convertir en probabilidades lo anterior entonces por cada flecha que sale de una palabra lo dividiremos entre el número total de flechas que sale de ésta palabra.\n",
    "\n",
    "![Ejemplo](imgs/NPL2.png)\n",
    "\n",
    "## ¿Cómo vamos a generar texto nuevo?\n",
    "\n",
    "Seguiremos las probabilidades dadas por la matriz de transición para ir de un estado inicial a un estado final y vamos a repetir éste proceso tanto como queramos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos Ocultos de Markov\n",
    "![Ejemplo de Modelo Oculto de Markov](imgs/HMM1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de probabilidad de la cadena de Markov asociada: \n",
      "[[0.21818182 0.27272727 0.50909091]]\n",
      "0.003909818181818177\n",
      "Secuencia más probable de clima para la secuencia de estados de ánimo feliz, feliz, triste.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.04105309090909085"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "transition_matrix = np.matrix([[0.5, 0.3, 0.2],  # Rainy \n",
    "                               [0.4, 0.2, 0.4],  # Cloudy\n",
    "                               [0, 0.3, 0.7]])   # Sunny\n",
    "emission_matrix = np.matrix([[0.9, 0.1], # Sad # Happy\n",
    "                             [0.6, 0.4],\n",
    "                             [0.2, 0.8]])\n",
    "\n",
    "distribution_of_markov_chain = find_distribution(transition_matrix, np.array([1, 0, 0]))\n",
    "print(\"Distribución de probabilidad de la cadena de Markov asociada: \")\n",
    "print(distribution_of_markov_chain)\n",
    "# La secuencia de estados será:\n",
    "# 0 -> Rainy\n",
    "# 1 -> Cloudy\n",
    "# 2 -> Sunny\n",
    "\n",
    "# Secuencia observada (en columnas):\n",
    "# 0 -> Sad\n",
    "# 1 -> Happy\n",
    "# observed_sequence = [2, 1, 2]\n",
    "\n",
    "def compute_probability(observed_sequence, state_sequence):\n",
    "    l1 = len(observed_sequence)\n",
    "    l2 = len(state_sequence)\n",
    "    if ((l1 < 1 or l2 < 1) or (l1 != l2)):\n",
    "        raise Exception()\n",
    "    p = distribution_of_markov_chain[0, state_sequence[0]]\n",
    "    for i in range(1, l2):\n",
    "        p *= transition_matrix[state_sequence[i - 1], state_sequence[i]]\n",
    "    for i in range(l1):\n",
    "        p *= emission_matrix[state_sequence[i], observed_sequence[i]]\n",
    "    return p\n",
    "\n",
    "\"\"\"\n",
    "    Calcularemos la siguiente probabilidad:\n",
    "    Día 1: Estuvo soleado y fuimos felices.\n",
    "    Día 2: Estuvo nublado y fuimos felices.\n",
    "    Día 3: Estuvo soleado y fuimos tristes.\n",
    "    Ésto se traducte en:\n",
    "    state_sequence = [2, 1, 2]\n",
    "    observed_sequence = [1, 1, 0]\n",
    "\"\"\"\n",
    "state_sequence = [2, 1, 2]\n",
    "observed_sequence = [1, 1, 0]\n",
    "print(compute_probability(observed_sequence, state_sequence))\n",
    "# ¿Cuál es la secuencia más probable de clima para los estados de ánimo dados?\n",
    "def compute_maximum_probability(unit_state_sequence, observed_sequence):\n",
    "    n = len(observed_sequence)\n",
    "    maximum_probability_of_sequence = 0\n",
    "    for sequence in itertools.product(unit_state_sequence, repeat=n):\n",
    "        maximum_probability_of_sequence = max(maximum_probability_of_sequence, compute_probability(observed_sequence, sequence))\n",
    "    return maximum_probability_of_sequence\n",
    "\n",
    "print(\"Secuencia más probable de clima para la secuencia de estados de ánimo feliz, feliz, triste.\")\n",
    "compute_maximum_probability([0, 1, 2], observed_sequence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

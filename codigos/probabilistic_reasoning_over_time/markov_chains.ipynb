{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cadenas de Markov \n",
    "Tambi√©n son llamados como procesos de Markov.\n",
    "## Definici√≥n\n",
    "Es un proceso estoc√°stico con la propiedad de que para cualquier conjunto sucesivo de \n",
    "$n$ tiempos tales que $t_{1} < t_{2} < \\dotsc < t_{n}$ se tiene que:\n",
    "$$\n",
    "    P_{1 | n - 1}\\left(y_{n} , t_{n} | y_{1}, t_{1}; \\dotsc ; y_{n - 1}, t_{n-1}\\right) = P_{1 | 1}\\left( y_n, t_n | y_{n - 1}, t_{n - 1}\\right)\n",
    "$$\n",
    "Esto es que la densidad de probabilidad condicionada a $t_{n}$ dada el valor $y_{n-1}$ a $t_{n-1}$ est√° un√≠vocamente determinada y no est√° afectada por lo que ocurre a tiempos anteriores. A $P_{1 | 1}$ se le conoce como la **probabilidad de transici√≥n**.\n",
    "## Definici√≥n (no tan formal).\n",
    "Una cadena o proceso de **Markov** es un proceso evolutivo que consiste de un n√∫mero finito de estados en cual la probabilidad de que ocurra un evento depende solamente del evento inmediatamente anterior con unas probabilidades que est√°n fijas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo\n",
    "## Mercado de valores\n",
    "![Cadena de Markov](imgs/Finance_Markov_chain_example_state_space.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los estados representan si un mercado burs√°til (hipot√©tico) muestra una tendencia alcista, bajista o de estancamiento durante una semana determinada. Seg√∫n la gr√°fica dirigida anterior, s√≠ pasamos una semana con tendencia alcista, entonces hay probabilidad de $90\\%$ que la siguiente semana sea con tendencia alcista, $7.5\\%$ de que sea una semana con tendencia a la baja y $2.5\\%$ de que la siguiente semana se estanque.\n",
    "Notemos que la gr√°fica anterior cumple lo siguiente:\n",
    "* **La pesos de todas las aristas que salen del estado $S$, suman $1$.**\n",
    "\n",
    "*Lo anterior se sigue de la definici√≥n de funci√≥n de probabilidad.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matriz de transici√≥n. \n",
    "$$\n",
    "    A =\n",
    "    \\begin{bmatrix}\n",
    "        0.9  & 0.075 & 0.025 \\\\\n",
    "        0.15 & 0.8   & 0.05 \\\\\n",
    "        0.25 & 0.25  & 0.5\n",
    "    \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidad de un mercado alcista:   0.6251513\n",
      "Probabilidad de un mercado bajista:   0.312436\n",
      "Probabilidad de un mercado estancado: 0.0624127\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "matrix_transition = np.matrix([[0.9, 0.075, 0.025], [0.15, 0.8, 0.05], [0.25, 0.25, 0.5]]) # Bull Market Bear Market Stagnant market\n",
    "\n",
    "def random_walk(num_iter):\n",
    "    init = np.random.randint(0, 3)\n",
    "    bull_market = 0\n",
    "    bear_market = 0\n",
    "    stagnant_market = 0\n",
    "    for i in range(num_iter):\n",
    "        r = np.random.rand()\n",
    "        if init == 0:\n",
    "            if r < 0.9:\n",
    "                bull_market += 1\n",
    "            elif r >= 0.9 and r < 0.975:\n",
    "                init = 1\n",
    "                bear_market += 1\n",
    "            else:\n",
    "                init = 2\n",
    "                stagnant_market += 1\n",
    "        elif init == 1:\n",
    "            if r < 0.15:\n",
    "                init = 0\n",
    "                bull_market += 1\n",
    "            elif r >= 0.15 and r < 0.95:\n",
    "                bear_market += 1\n",
    "            else: \n",
    "                init = 2\n",
    "                stagnant_market += 1\n",
    "        else:\n",
    "            if r < 0.25:\n",
    "                init = 0\n",
    "                bull_market += 1\n",
    "            elif r >= 0.25 and r < 0.5:\n",
    "                init = 1\n",
    "                bear_market += 1\n",
    "            else:\n",
    "                stagnant_market += 1\n",
    "    return (bull_market, bear_market, stagnant_market)\n",
    "    \n",
    "markets = random_walk(10000000)\n",
    "total = markets[0] + markets[1] + markets[2]\n",
    "print(\"Probabilidad de un mercado alcista:   \" + str(markets[0] / total))\n",
    "print(\"Probabilidad de un mercado bajista:   \" + str(markets[1] / total))\n",
    "print(\"Probabilidad de un mercado estancado: \" + str(markets[2] / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribuci√≥n estacionaria\n",
    "Sea $p^{(t)}$ la probabilidad de la distribuci√≥n despu√©s de $t$ pasos de un *random walk*. Definimos la distribuci√≥n de probabilidad $a^{(t)}$ como sigue:\n",
    "$$\n",
    "    a^{(t)} = \\frac{1}{t}\\left(p^{(0)} + p^{(1)} + \\dotsc + p^{(t - 1)}\\right)\n",
    "$$\n",
    "Es decir, √©sta distribuci√≥n de probabilidad **no cambia con el tiempo** en la cadena de Markov."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teorema Fundamental de las cadenas de Markov\n",
    "Para toda cadena de Markov conectada existe un √∫nico vector $\\pi$ de probabilidad que satisface:\n",
    "$$\n",
    "    \\pi P = \\pi\n",
    "$$\n",
    "donde $P$ es la matriz de transici√≥n asociada a la cadena de Markov. M√°s a√∫n, para cualquier distribuci√≥n inicial, $\\displaystyle\\lim_{t \\to \\infty} a^{t}$ existe y es igual a $\\pi$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.625  0.3125 0.0625]]\n"
     ]
    }
   ],
   "source": [
    "bull_market = np.array([1, 0, 0]) # Supongamos que en el tiempo t = 0 es una semana con tendencia alcista.\n",
    "\n",
    "def find_distribution(matrix_transition, init):\n",
    "    pi = np.dot(init, matrix_transition)\n",
    "    while (pi != init).any():\n",
    "        init = pi\n",
    "        pi = np.dot(init, matrix_transition)\n",
    "    return pi\n",
    "\n",
    "print(find_distribution(matrix_transition, bull_market))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notemos que nuestra aproximaci√≥n ejecutando *random walk*  es bastante buena y que de hecho cada vez que el n√∫mero de iteraciones es m√°s grande se va aproximando m√°s al m√©todo con los vectores.\n",
    "\n",
    "Notemos que como el vector $\\pi$ denota una distribuci√≥n de probabilidad entonces, el total de la suma de sus componentes es $1$.\n",
    "\n",
    "As√≠ por lo que obtuvimos anteriormente concluimos lo siguiente:\n",
    "* El $62.5 \\%$ de las semanas ser√°n a la alza.\n",
    "* El $31.25 \\%$ de las semanas se estancar√°n.\n",
    "* El $6.25 \\%$ de las semanas ser√°n a la baja."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Irreducibilidad y Recurrencia\n",
    "![Cadena de Markov](imgs/cadena_de_markov_1.png)\n",
    "\n",
    "Veamos el estado $0$.\n",
    "Notemos que s√≠ hacemos varios *random walk* sobre la cadena de Markov anterior iniciando en el estado $0$, habr√° caminos que no saldr√°n del estado $0$, es decir, se quedar√°n en un **loop** sin embargo habr√°n caminos que saldr√°n del estado $0$ y no volver√°n, ya que no hay ninguna flecha que vaya al estado $0$ desde el estado $1$ o $2$. As√≠ notemos que la probabilidad que tiene un *random walk* de revisitar el estado $0$ es menor que $1$, al estado $0$ se le conoce como **estado transitorio**.\n",
    "\n",
    "Supongamos ahora que queremos hacer un *random walk* desde el estado $1$, as√≠ podemos notar que despu√©s de un tiempo volvemos a visitar el estado $1$, notemos que √©sto tambi√©n lo cumple el estado $2$. As√≠ la probabilidad de revisitar al estado $1$ es $1$ *(es an√°logo para el estado $2$)*. A estos estados se les conoce como **estados recurrentes**.\n",
    "\n",
    "## Reducible\n",
    "Decimos que una cadena de Markov es reducible s√≠ existen en ella **estados transitorios**\n",
    "\n",
    "Notemos que a la cadena de Markov de √©sta secci√≥n podemos hacer que todos sus estados sean **recurrentes** creando una flecha del estado $2$ al estado $0$.\n",
    "\n",
    "![Cadena de Markov con estados recurrentes](imgs/cadena_de_markov_2.png)\n",
    "\n",
    "A √©sto le llamamos que una cadena de Markov sea irreducible, cuando todos sus estados son recurrentes.\n",
    "\n",
    "## Clases\n",
    "\n",
    "Una clase en una cadena de Markov es un subcadena de Markov que es irreducible.\n",
    "\n",
    "![Clases](imgs/cadena_de_markov_3.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cadenas de Markov en $n$ pasos\n",
    "## ¬øCu√°l es la probabilidad de alcanzar a un estado $j$ desde un estado $i$ en exactamente $n$ pasos?\n",
    "As√≠ denotamos a $P_{ij}(n)$ como la probabilidad antes mencionada.\n",
    "## Ejemplo \n",
    "¬øCu√°l es la probabilidad de alcanzar el estado **Bull Market** desde el estado **Stagnant market** en exactamente $1$ paso?\n",
    "### Respuesta\n",
    "$0.25$\n",
    "¬øCu√°l es la probabilidad de alcanzar el estado **Bull Market** desde el estado **Stagnant market** en exactamente $2$ pasos?\n",
    "### Respuesta\n",
    "* **Stagnant Market** a **Bull Market** y de **Bull Market** a **Bull Market** esto es igual a $0.25 \\times 0.9$\n",
    "* **Stagnant Market** a **Stagnant Market** y de **Stagnant Market** a **Bull Market** esto es igual a $0.5 \\times 0.25$\n",
    "* **Stagnant Market** a **Bear Market** y de **Bear Market** a **Bull Market** esto es igual a $0.25 \\times 0.15$\n",
    "* **Total:** $0.25 \\times 0.9 + 0.5 \\times 0.25 + 0.25 \\times 0.15 = 0.3875$\n",
    "\n",
    "Notemos que lo anterior es:\n",
    "$A_{20} \\times A_{00} + A_{22} \\times A_{21} + A_{21} \\times A_{10}$\n",
    "Que es igual a:\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    A_{20} & A_{21} & A_{22}\n",
    "\\end{bmatrix}\n",
    "\\times\n",
    "\\begin{bmatrix}\n",
    "    A_{00} \\\\\n",
    "    A_{10} \\\\\n",
    "    A_{20}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "De manera general tenemos que:\n",
    "$$\n",
    "    P_{ij}(n) = A^{n}_{ij}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidad para 2 pasos: 0.03875000000000001\n"
     ]
    }
   ],
   "source": [
    "print(\"Probabilidad para 2 pasos: \" +  str(np.linalg.matrix_power(matrix_transition, 2)[0,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidad para los primeros 15 pasos iniciando desde Stagnant market y terminando en Bull market: \n",
      "Probabilidad para 1 pasos: 0.025\n",
      "Probabilidad para 2 pasos: 0.03875000000000001\n",
      "Probabilidad para 3 pasos: 0.04675000000000001\n",
      "Probabilidad para 4 pasos: 0.05167500000000001\n",
      "Probabilidad para 5 pasos: 0.05486500000000002\n",
      "Probabilidad para 6 pasos: 0.057018500000000014\n",
      "Probabilidad para 7 pasos: 0.05851810000000002\n",
      "Probabilidad para 8 pasos: 0.059585430000000016\n",
      "Probabilidad para 9 pasos: 0.06035636200000002\n",
      "Probabilidad para 10 pasos: 0.06091858820000002\n",
      "Probabilidad para 11 pasos: 0.06133114276000002\n",
      "Probabilidad para 12 pasos: 0.06163505132400002\n",
      "Probabilidad para 13 pasos: 0.06185947305040002\n",
      "Probabilidad para 14 pasos: 0.06202545021032003\n",
      "Probabilidad para 15 pasos: 0.062148319415248024\n"
     ]
    }
   ],
   "source": [
    "def probability_of_n_steps(matrix_transition, n, i, j):\n",
    "    return np.linalg.matrix_power(matrix_transition, n)[i, j]\n",
    "\n",
    "print(\"Probabilidad para los primeros 15 pasos iniciando desde Stagnant market y terminando en Bull market: \")\n",
    "for i in range(1, 16):\n",
    "    print(\"Probabilidad para \" + str(i) + \" pasos: \" + str(probability_of_n_steps(matrix_transition, i, 0, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo anterior es posible gracias al **Teorema Chapman-Kolmogorov** que establece lo siguiente:\n",
    "$$\n",
    "    P_{ij}(n) = \\sum_{k} P_{ik}(r) \\times P_{kj}(n-r)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def limit_n_to_infty(transition_matrix):\n",
    "    init = transition_matrix\n",
    "    i = 2\n",
    "    transition_matrix = np.linalg.matrix_power(transition_matrix, i)\n",
    "    while (transition_matrix != init).any():\n",
    "        init = transition_matrix\n",
    "        i += 1\n",
    "        transition_matrix = np.linalg.matrix_power(init, i)\n",
    "    return transition_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicaci√≥n de la cadenas de Markov: Generaci√≥n de texto.\n",
    "Las cadenas de Markov nos ayudan a creer modelos de lenguaje.\n",
    "Para tener una cadena de Markov necesitamos lo siguiente:\n",
    "* Un conjunto de estados.\n",
    "* Transiciones entre √©stos estados.\n",
    "\n",
    "Para generar texto vamos a hacer que las palabras sean estados.\n",
    "Supongamos que tenemos dos palabras $i$ y $j$ para calcular la probabilidad $P_{ij}$ lo √∫nico que necesitamos realizar es buscar en nuestro texto la probabilidad de que la siguiente palabra sea $j$ dado que la palabra actual es $i$ esto es:\n",
    "$$\n",
    "    P_{ij} = P\\left( n + 1 = j | n = i \\right)\n",
    "$$\n",
    "S√≠ no existe que la palabra $j$ est√° despu√©s que la palabra $i$ entonces la probabilidad ser√° $0$\n",
    "## Ejemplo\n",
    "\n",
    "*My name is Sherlock Holmes. It is my business to know what other people do not know.*\n",
    "\n",
    "![Ejemplo](imgs/NPL1.png)\n",
    "\n",
    "El n√∫mero de cada flecha es el n√∫mero de veces que una palabra aparece previamente a la que apunta.\n",
    "\n",
    "Para convertir en probabilidades lo anterior entonces por cada flecha que sale de una palabra lo dividiremos entre el n√∫mero total de flechas que sale de √©sta palabra.\n",
    "\n",
    "![Ejemplo](imgs/NPL2.png)\n",
    "\n",
    "## ¬øC√≥mo vamos a generar texto nuevo?\n",
    "\n",
    "Seguiremos las probabilidades dadas por la matriz de transici√≥n para ir de un estado inicial a un estado final y vamos a repetir √©ste proceso tanto como queramos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos Ocultos de Markov\n",
    "![Ejemplo de Modelo Oculto de Markov](imgs/HMM1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Matriz de transici√≥n y Matriz de emisi√≥n](imgs/transition_matrix_and_emission_matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representamos los estados de la **cadena de markov** mediante la variable aleatoria $X$ y representamos las observaciones mediante la variable aleatoria $Y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Matem√°ticamente** hablando la entrada $(i, j)$ de la **matriz de transici√≥n** nos representa la siguiente probabilidad:\n",
    "$$\n",
    "    P\\left( X = j \\ | \\ X = i \\right)\n",
    "$$\n",
    "Ejemplificando en nuestra matriz transici√≥n la entrada $(2, 3)$ representa la siguiente probabilidad:\n",
    "**La probabilidad de que hoy sea un d√≠a soleado dado que ayer fue un d√≠a nublado**\n",
    "\n",
    "Matematicamente hablando ser√≠a:\n",
    "\n",
    "$P($ ‚òÄÔ∏è $|$ ‚òÅÔ∏è $)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Matem√°ticamente** hablando la entrada $(i, j)$ de la **matriz de emisi√≥n** nos representa la siguiente probabilidad:\n",
    "$$\n",
    "    P\\left( Y = j \\ | \\ X = i \\right)\n",
    "$$\n",
    "Ejemplificando en nuestra matriz transici√≥n la entrada $(2, 2)$ representa la siguiente probabilidad:\n",
    "**La probabilidad de que hoy seamos felices soleado dado que hoy es un d√≠a nublado**\n",
    "\n",
    "Matematicamente hablando ser√≠a:\n",
    "\n",
    "$P($ üòÄ  $|$ ‚òÅÔ∏è $)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    La secuencia de estados seguir√° la siguiente notaci√≥n:\\n\\n    0 -> Rainy\\n    1 -> Cloudy\\n    2 -> Sunny\\n\\n    Secuencia de observaciones (en columnas) seguir√° la siguiente notaci√≥n:\\n\\n    0 -> Sad\\n    1 -> Happy\\n\\n    Con la notaci√≥n anterior, calcularemos \\n    la siguiente probabilidad:\\n    \\n    D√≠a 1: Estuvo soleado y fuimos felices.\\n    D√≠a 2: Estuvo nublado y fuimos felices.\\n    D√≠a 3: Estuvo soleado y fuimos tristes.\\n    √âsto se traducte en:\\n    state_sequence = [2, 1, 2]\\n    observed_sequence = [1, 1, 0]\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "                            # Rainy  Cloudy Sunny\n",
    "transition_matrix = np.matrix([[0.5, 0.3, 0.2],  # Rainy \n",
    "                               [0.4, 0.2, 0.4],  # Cloudy\n",
    "                               [0, 0.3, 0.7]])   # Sunny\n",
    "                            # Sad # Happy\n",
    "emission_matrix = np.matrix([[0.9, 0.1],    # Rainy \n",
    "                             [0.6, 0.4],    # Cloudy\n",
    "                             [0.2, 0.8]])   # Sunny\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    La secuencia de estados seguir√° la siguiente notaci√≥n:\n",
    "\n",
    "    0 -> Rainy\n",
    "    1 -> Cloudy\n",
    "    2 -> Sunny\n",
    "\n",
    "    Secuencia de observaciones (en columnas) seguir√° la siguiente notaci√≥n:\n",
    "\n",
    "    0 -> Sad\n",
    "    1 -> Happy\n",
    "\n",
    "    Con la notaci√≥n anterior, calcularemos \n",
    "    la siguiente probabilidad:\n",
    "    \n",
    "    D√≠a 1: Estuvo soleado y fuimos felices.\n",
    "    D√≠a 2: Estuvo nublado y fuimos felices.\n",
    "    D√≠a 3: Estuvo soleado y fuimos tristes.\n",
    "    √âsto se traducte en:\n",
    "    state_sequence = [2, 1, 2]\n",
    "    observed_sequence = [1, 1, 0]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculemos la siguiente probabilidad:\n",
    "\n",
    "![](imgs/probabilidad_de_ejemplo.png)\n",
    "\n",
    "Matem√°ticamente hablando tenemos que calcular la siguiente probabilidad conjunta:\n",
    "\n",
    "![](imgs/probabilidad_conjunta.png)\n",
    "\n",
    "Por la **propiedad de las cadenas de Markov** podemos calcular lo anterior de la siguiente manera:\n",
    "\n",
    "![](imgs/probabilidad_desglosada.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribuci√≥n de probabilidad de la cadena de Markov asociada: \n",
      "[[0.21818182 0.27272727 0.50909091]]\n"
     ]
    }
   ],
   "source": [
    "stationary_distribution_of_markov_chain = find_distribution(transition_matrix, np.array([1, 0, 0]))\n",
    "print(\"Distribuci√≥n de probabilidad de la cadena de Markov asociada: \")\n",
    "print(stationary_distribution_of_markov_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def compute_probability(observed_sequence, state_sequence, stationary_distribution):\n",
    "    l1 = len(observed_sequence)\n",
    "    l2 = len(state_sequence)\n",
    "    if ((l1 < 1 or l2 < 1) or (l1 != l2)):\n",
    "        raise Exception()\n",
    "    p = stationary_distribution[0, state_sequence[0]]\n",
    "    for i in range(1, l2):\n",
    "        p *= transition_matrix[state_sequence[i - 1], state_sequence[i]]\n",
    "    for i in range(l1):\n",
    "        p *= emission_matrix[state_sequence[i], observed_sequence[i]]\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003909818181818178\n"
     ]
    }
   ],
   "source": [
    "state_sequence = [2, 1, 2]\n",
    "observed_sequence = [1, 1, 0]\n",
    "print(compute_probability(observed_sequence, state_sequence, stationary_distribution_of_markov_chain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por definici√≥n en el **Modelo Oculto de Markov** no tenemos acceso a los estados entonces tenemos que calcular la secuencia de estados m√°s probable para las observaciones que se nos proporcionan.\n",
    "En nuestro caso vamos a calcular la secuencia de estado m√°s probable para las observaciones: feliz, feliz, triste.\n",
    "\n",
    "![](imgs/secuencia_de_observaciones.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La probabilidad m√°s alta para la secuencia de estados de √°nimo: feliz, feliz, triste.\n",
      "0.04105309090909086\n",
      "Cuyos estados son: \n",
      " Soleado  Soleado  Nublado \n"
     ]
    }
   ],
   "source": [
    "# ¬øCu√°l es la secuencia m√°s probable de clima para los estados de √°nimo dados?\n",
    "def compute_maximum_probability(unit_state_sequence, observed_sequence, stationary_distribution):\n",
    "    n = len(observed_sequence)\n",
    "    maximum_probability_of_sequence = 0\n",
    "    maximum_sequence = ()\n",
    "    for sequence in itertools.product(unit_state_sequence, repeat=n):\n",
    "        p = compute_probability(observed_sequence, sequence, stationary_distribution)\n",
    "        if (maximum_probability_of_sequence < p):\n",
    "            maximum_probability_of_sequence = p\n",
    "            maximum_sequence = sequence\n",
    "    return (maximum_probability_of_sequence, maximum_sequence)\n",
    "\n",
    "\n",
    "def return_states(states_sequence):\n",
    "    n = len(states_sequence)\n",
    "    s = \"\"\n",
    "    for i in range(n):\n",
    "        if states_sequence[i] == 0:\n",
    "            s += \" Lluvioso \"\n",
    "        elif states_sequence[i] == 1:\n",
    "            s += \" Nublado \"\n",
    "        else:\n",
    "            s += \" Soleado \"\n",
    "    return s\n",
    "\n",
    "probability, states = compute_maximum_probability([0, 1, 2], observed_sequence, stationary_distribution_of_markov_chain)\n",
    "print(\"La probabilidad m√°s alta para la secuencia de estados de √°nimo: feliz, feliz, triste.\")\n",
    "print(probability)\n",
    "print(\"Cuyos estados son: \")\n",
    "print(return_states(states))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formalizaci√≥n de los Modelos Ocultos de Markov\n",
    "## Predicci√≥n de cadenas\n",
    "## Propiedad de M√°rkov\n",
    "Suponemos que las variables de emisi√≥n $Y_{i}$ cumplen con la propiedad de M√°rkov, esto es:\n",
    "$$\n",
    "    p\\left( y_{t} | y_{1}, \\dotsc, y_{t - 1} \\right) = p\\left( y_{t} | y_{t - 1} \\right)\n",
    "$$\n",
    "## Definici√≥n\n",
    "Un Modelo Oculto de M√°rkov es una tupla $HMM = \\left( X, Y, A, \\Pi, B \\right)$ donde:\n",
    "* $X = \\{ x_{1}, \\dotsc, x_{t} \\}$ son observaciones y $Y = \\{y_{1}, \\dotsc, y_{k} \\}$ son emisiones.\n",
    "* $A_{i,j} = p\\left(y_{j} | y_{i} \\right)$ y $\\Pi_{i} = p(y_{i})$ es el modelo de transici√≥n.\n",
    "* $A$ matriz.\n",
    "* $\\Pi$ vector.\n",
    "* $B_{i,j} = p(x_{j}, y_{i})$ es el modelo sensor.\n",
    "* $B$ matriz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En nuestro *Modelo Oculto de Markov* \n",
    "* $X = \\{\\text{Triste}, \\text{Feliz} \\}$\n",
    "* $Y = \\{\\text{Lluvioso}, \\text{Nublado}, \\text{Soleado} \\}$\n",
    "* $A = \\begin{bmatrix}\n",
    "        0.5  & 0.3 & 0.2 \\\\\n",
    "        0.4  & 0.2 & 0.4 \\\\\n",
    "        0    & 0.3 & 0.7\n",
    "    \\end{bmatrix}$\n",
    "* $\\Pi = \\begin{bmatrix}\n",
    "        1  & 0 & 0\n",
    "    \\end{bmatrix}$\n",
    "* $B = \n",
    "    \\begin{bmatrix}\n",
    "        0.9  & 0.1 \\\\\n",
    "        0.6  & 0.4 \\\\\n",
    "        0.2  & 0.8\n",
    "    \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def viterbi(states, \n",
    "            stationary_distribution, \n",
    "            transition_matrix, \n",
    "            emission_matrix, \n",
    "            observed_sequence):\n",
    "    T = len(observed_sequence)\n",
    "    S = len(states)\n",
    "    prob = np.zeros((T, S))\n",
    "    prev = np.zeros((T, S))\n",
    "    for state in states:\n",
    "        prob[0, state] = stationary_distribution[0, state] * emission_matrix[state, observed_sequence[0]]\n",
    "    for t in range(1, T):\n",
    "        for s in states:\n",
    "            for r in states:\n",
    "                new_prob = emission_matrix[s, observed_sequence[t]] * transition_matrix[r, s] * prob[t - 1, r]\n",
    "                if new_prob > prob[t, s]:\n",
    "                    prob[t, s] = new_prob\n",
    "                    prev[t, s] = r\n",
    "    path = np.array([0] * T, dtype=np.uint32)\n",
    "    path[T - 1] = np.argmax(prob[T - 1])\n",
    "    for t in range(T - 2, -1, -1):\n",
    "        path[t] = prev[t + 1, path[s]]\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La secuencia de estados con probabilidad m√°s alta para la secuencia de observaciones feliz, feliz, triste es: \n",
      " Soleado  Soleado  Nublado \n"
     ]
    }
   ],
   "source": [
    "most_likely_states_sequence = viterbi([0, 1, 2], \n",
    "                                      stationary_distribution_of_markov_chain, \n",
    "                                      transition_matrix, \n",
    "                                      emission_matrix, \n",
    "                                      observed_sequence)\n",
    "print(\"La secuencia de estados con probabilidad m√°s alta para la secuencia de observaciones feliz, feliz, triste es: \")\n",
    "print(return_states(most_likely_states_sequence))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
